{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9443631,"sourceType":"datasetVersion","datasetId":5739163}],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Initialization","metadata":{}},{"cell_type":"markdown","source":"## Import libraries","metadata":{}},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')\n\nimport torch\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport cv2\nimport os\nimport seaborn as sns\n\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import StratifiedKFold\n\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torchvision import models\nfrom torch.optim import AdamW\nfrom torch.utils.data import Dataset, DataLoader\n\nfrom tqdm.auto import tqdm\n\nimport ssl # Quickfix to torchaudio ssl error\nssl._create_default_https_context = ssl._create_unverified_context\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2024-09-20T22:38:23.373489Z","iopub.execute_input":"2024-09-20T22:38:23.374210Z","iopub.status.idle":"2024-09-20T22:38:27.648375Z","shell.execute_reply.started":"2024-09-20T22:38:23.374167Z","shell.execute_reply":"2024-09-20T22:38:27.647316Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# Preprocessing","metadata":{}},{"cell_type":"markdown","source":"## Helper Function","metadata":{}},{"cell_type":"code","source":"def preprocessing(image):\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert to RGB\n    image = cv2.resize(image, (224, 224))  # Resize to 224x224\n    image = image / 255.0  # Normalize to [0, 1]\n    image = np.transpose(image, (2, 0, 1))  # Convert to (C, H, W)\n    image = torch.tensor(image, dtype=torch.float32)\n    return image\n\ndef show_image(dataloader, index):\n    # Get a batch of data\n    data_iter = iter(dataloader)\n    images, labels = next(data_iter)\n\n    # Ensure the index is within the batch size\n    batch_size = images.size(0)\n    if index >= batch_size:\n        raise IndexError(f\"Index {index} is out of bounds for batch size {batch_size}\")\n\n    # Get the image and label at the specified index within the batch\n    image = images[index]\n    label = labels[index]\n\n    # If images were normalized, we might need to denormalize them\n    # For example, if we used transforms.Normalize(mean, std), we need to unnormalize\n    # Replace these mean and std values with those used in your transforms\n    mean = torch.tensor([0.485, 0.456, 0.406])\n    std = torch.tensor([0.229, 0.224, 0.225])\n    image = image * std[:, None, None] + mean[:, None, None]\n\n    # Convert tensor to numpy array\n    image_np = image.numpy().transpose((1, 2, 0))\n\n    # Clip values to [0,1] if necessary\n    image_np = np.clip(image_np, 0, 1)\n\n    plt.figure(figsize=(6, 6))\n    plt.title(f\"Label: {label.item()}\")  # Use label name if available\n    plt.imshow(image_np)\n    plt.axis('off')  # Hide axis ticks\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-09-20T22:38:33.601465Z","iopub.execute_input":"2024-09-20T22:38:33.602006Z","iopub.status.idle":"2024-09-20T22:38:33.612001Z","shell.execute_reply.started":"2024-09-20T22:38:33.601967Z","shell.execute_reply":"2024-09-20T22:38:33.611009Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"## Custom Dataset","metadata":{}},{"cell_type":"code","source":"import os\nimport cv2\nimport torch\nfrom torch.utils.data import Dataset\nimport torch.nn.functional as F\nfrom torchvision import transforms\n\nclass Resize:\n    def __init__(self, size):\n        self.size = size  # (h, w)\n\n    def __call__(self, image):\n        image = F.interpolate(image.unsqueeze(0), size=self.size, mode='bilinear', align_corners=False)\n        return image.squeeze(0)\n\nclass SkinDataset(Dataset):\n    def __init__(self, root_dir, transform=None):\n        self.root_dir = root_dir\n        self.transform = transform\n        self.image_paths = []\n        self.labels = []\n        self.label_to_index = {}\n        \n        self._build_label_index()\n\n    def _build_label_index(self):\n        label_names = sorted([\n            d for d in os.listdir(self.root_dir)\n            if os.path.isdir(os.path.join(self.root_dir, d))\n        ])\n        \n        self.label_to_index = {label_name: idx for idx, label_name in enumerate(label_names)}\n        \n        for label_name in label_names:\n            label_dir = os.path.join(self.root_dir, label_name)\n            label_index = self.label_to_index[label_name]\n            for img_name in os.listdir(label_dir):\n                img_path = os.path.join(label_dir, img_name)\n                if img_name.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif')):\n                    self.image_paths.append(img_path)\n                    self.labels.append(label_index)\n\n    def __len__(self):\n        return len(self.image_paths)\n\n    def __getitem__(self, idx):\n        img_path = self.image_paths[idx]\n        label = self.labels[idx]\n\n        image = cv2.imread(img_path)\n        if image is None:\n            raise ValueError(f\"Failed to load image at path: {img_path}\")\n\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\n        image = torch.from_numpy(image).permute(2, 0, 1).float() / 255.0  # Shape: (C, H, W)\n\n        if self.transform:\n            image = self.transform(image)\n        else:\n            image = F.interpolate(image.unsqueeze(0), size=(224, 224), mode='bilinear', align_corners=False).squeeze(0)\n\n        return image, label","metadata":{"execution":{"iopub.status.busy":"2024-09-20T22:38:35.429759Z","iopub.execute_input":"2024-09-20T22:38:35.430377Z","iopub.status.idle":"2024-09-20T22:38:35.445607Z","shell.execute_reply.started":"2024-09-20T22:38:35.430336Z","shell.execute_reply":"2024-09-20T22:38:35.444834Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"from torchvision import transforms\n\ndata_transforms = transforms.Compose([\n    Resize((224, 224)),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                         std=[0.229, 0.224, 0.225]),\n])\n\ntrain_dataset = SkinDataset(root_dir='/kaggle/input/lesion-image/dataset/Train', transform=data_transforms)\ntest_dataset = SkinDataset(root_dir='/kaggle/input/lesion-image/dataset/Test', transform=data_transforms)\nvalid_dataset = SkinDataset(root_dir='/kaggle/input/lesion-image/dataset/Valid', transform=data_transforms)\n\nprint(train_dataset.label_to_index)\n\nfrom torch.utils.data import DataLoader\n\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=True)\nvalid_loader = DataLoader(valid_dataset, batch_size=32, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2024-09-20T22:38:36.977854Z","iopub.execute_input":"2024-09-20T22:38:36.978257Z","iopub.status.idle":"2024-09-20T22:38:38.624260Z","shell.execute_reply.started":"2024-09-20T22:38:36.978217Z","shell.execute_reply":"2024-09-20T22:38:38.623323Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"{'Chickenpox': 0, 'Cowpox': 1, 'HFMD': 2, 'Healthy': 3, 'Measles': 4, 'Monkeypox': 5, 'akiec': 6, 'bcc': 7, 'bkl': 8, 'df': 9, 'mel': 10, 'nv': 11, 'vasc': 12}\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Modeling","metadata":{}},{"cell_type":"markdown","source":"## Model construction","metadata":{}},{"cell_type":"code","source":"class MobileNetV3Model(nn.Module):\n    def __init__(self, num_classes, extractor_trainable: bool = True):\n        super(MobileNetV3Model, self).__init__()\n        mobilenet = models.mobilenet_v3_large(pretrained=True)\n        \n        self.feature_extractor = mobilenet.features\n        \n        for param in self.feature_extractor.parameters():\n            param.requires_grad = extractor_trainable\n        \n        self.out_features = mobilenet.classifier[0].in_features\n\n        self.classifier = nn.Sequential(\n            nn.Linear(self.out_features, num_classes)\n        )\n\n    def forward(self, x):\n        x = self.feature_extractor(x)\n        \n        x = F.adaptive_avg_pool2d(x, 1).reshape(x.size(0), -1)\n        \n        x = self.classifier(x)\n        \n        return x","metadata":{"execution":{"iopub.status.busy":"2024-09-20T22:38:41.127644Z","iopub.execute_input":"2024-09-20T22:38:41.128017Z","iopub.status.idle":"2024-09-20T22:38:41.135500Z","shell.execute_reply.started":"2024-09-20T22:38:41.127979Z","shell.execute_reply":"2024-09-20T22:38:41.134461Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"class ResNetModel(nn.Module):\n    def __init__(self, num_classes, extractor_trainable=True):\n        super(ResNetModel, self).__init__()\n        resnet = models.resnet34(pretrained=True)\n        \n        if not extractor_trainable:\n            for param in resnet.parameters():\n                param.requires_grad = False\n        \n        self.feature_extractor = nn.Sequential(*list(resnet.children())[:-1])\n        num_features = resnet.fc.in_features\n        self.fc = nn.Linear(num_features, num_classes)\n\n    def forward(self, x):\n        x = self.feature_extractor(x)\n        x = torch.flatten(x, 1)\n        x = self.fc(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2024-09-20T22:38:42.846680Z","iopub.execute_input":"2024-09-20T22:38:42.846995Z","iopub.status.idle":"2024-09-20T22:38:42.854198Z","shell.execute_reply.started":"2024-09-20T22:38:42.846963Z","shell.execute_reply":"2024-09-20T22:38:42.853119Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"# Training and Validation Loop","metadata":{}},{"cell_type":"code","source":"def training_loop(model, epochs, optimizer, loss_fn, data_loader, device, fold=0):\n    epoch_losses = []\n    \n    for epoch in range(epochs):\n        loop = tqdm(data_loader, total=len(data_loader), leave=False)\n        model.train()\n        mean_loss = 0\n\n        for _, (X, y) in enumerate(loop):\n            optimizer.zero_grad()\n\n            X, y = X.to(device), y.to(device)\n            \n            pred = model(X)\n            \n            loss = loss_fn(pred, y)\n            mean_loss += loss.item()\n            \n            loss.backward()\n            optimizer.step()\n\n            loop.set_description(f\"Epoch [{epoch+1}/{epochs}]\")\n            loop.set_postfix(loss=loss.item())\n        \n        mean_loss /= len(data_loader)\n        epoch_losses.append(mean_loss)\n        \n        print(f\"Epoch [{epoch+1}/{epochs}] completed. Avg loss: {mean_loss:.4f}\")\n        \n    print(f\"Training fold {fold+1} completed.\")\n    \n    return epoch_losses","metadata":{"execution":{"iopub.status.busy":"2024-09-20T22:38:45.433035Z","iopub.execute_input":"2024-09-20T22:38:45.433978Z","iopub.status.idle":"2024-09-20T22:38:45.441742Z","shell.execute_reply.started":"2024-09-20T22:38:45.433936Z","shell.execute_reply":"2024-09-20T22:38:45.440780Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import fbeta_score","metadata":{"execution":{"iopub.status.busy":"2024-09-20T22:38:48.364239Z","iopub.execute_input":"2024-09-20T22:38:48.365106Z","iopub.status.idle":"2024-09-20T22:38:48.368986Z","shell.execute_reply.started":"2024-09-20T22:38:48.365039Z","shell.execute_reply":"2024-09-20T22:38:48.368117Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def validation_loop(model, loss_fn, data_loader, device):\n    model.eval()\n    size = len(data_loader.dataset)\n    num_batches = len(data_loader)\n    test_loss, correct = 0.0, 0\n    all_preds, all_labels = [], []\n\n    with torch.no_grad():\n        for X, y in data_loader:\n            X, y = X.to(device), y.to(device)\n\n            # Forward pass\n            outputs = model(X)\n\n            # Calculate loss\n            loss = loss_fn(outputs, y)\n            test_loss += loss.item()\n\n            # Get predicted classes\n            _, pred_labels = torch.max(outputs, 1)\n\n            # Calculate number of correct predictions\n            correct += (pred_labels == y).sum().item()\n\n            # Move tensors to CPU and convert to numpy arrays\n            pred_labels = pred_labels.cpu().numpy()\n            y = y.cpu().numpy()\n\n            # Store predictions and true labels for metrics\n            all_preds.extend(pred_labels)\n            all_labels.extend(y)\n\n    # Average loss and accuracy\n    test_loss /= num_batches\n    accuracy = (correct / size) * 100\n\n    print(f\"Validation Error:\\n Accuracy: {accuracy:.2f}%, Avg loss: {test_loss:.4f}\\n\")\n\n    # Calculate confusion matrix\n    conf_matrix = confusion_matrix(all_labels, all_preds)\n\n    # Calculate F-beta score with beta=2\n    fbeta = fbeta_score(all_labels, all_preds, beta=2, average='weighted')\n\n    print(f\"F-beta Score (beta=2): {fbeta:.4f}\\n\")\n\n    return conf_matrix, accuracy, (all_labels, all_preds), fbeta","metadata":{"execution":{"iopub.status.busy":"2024-09-20T22:38:52.466124Z","iopub.execute_input":"2024-09-20T22:38:52.466507Z","iopub.status.idle":"2024-09-20T22:38:52.475854Z","shell.execute_reply.started":"2024-09-20T22:38:52.466470Z","shell.execute_reply":"2024-09-20T22:38:52.474971Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"## Model training","metadata":{}},{"cell_type":"code","source":"from torch import optim","metadata":{"execution":{"iopub.status.busy":"2024-09-20T22:38:56.783488Z","iopub.execute_input":"2024-09-20T22:38:56.783861Z","iopub.status.idle":"2024-09-20T22:38:56.787969Z","shell.execute_reply.started":"2024-09-20T22:38:56.783825Z","shell.execute_reply":"2024-09-20T22:38:56.787053Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"def calculate_class_weights(dataset):\n    \"\"\"\n    Calculate class weights based on the frequency of each class in the dataset.\n    \n    Args:\n        dataset: A PyTorch dataset (e.g., DiabeticDataset).\n        \n    Returns:\n        class_weights: A tensor of class weights to be used in the loss function.\n    \"\"\"\n    # Get the labels from the dataset\n    labels = [label for _, label in dataset]\n\n    # Count the frequency of each class\n    class_counts = np.bincount(labels)\n    \n    # Calculate weights as the inverse of the frequency of each class\n    class_weights = 1.0 / class_counts\n    \n    # Normalize the weights to ensure stability\n    class_weights = class_weights / class_weights.sum()\n\n    # Convert the weights to a PyTorch tensor\n    class_weights = torch.tensor(class_weights, dtype=torch.float32)\n    \n    return class_weights\n\n# Usage:\n# Calculate class weights based on the training dataset\nclass_weights = calculate_class_weights(train_dataset)\n\n# Move the class weights to the appropriate device\nclass_weights = class_weights.to(device)\n\n# Define the loss function with class weights\ncriterion = nn.CrossEntropyLoss(weight=class_weights)","metadata":{"execution":{"iopub.status.busy":"2024-09-20T22:39:03.622827Z","iopub.execute_input":"2024-09-20T22:39:03.623557Z","iopub.status.idle":"2024-09-20T22:40:33.613563Z","shell.execute_reply.started":"2024-09-20T22:39:03.623518Z","shell.execute_reply":"2024-09-20T22:40:33.612640Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"model = ResNetModel(13).to(device)\n\n# criterion = nn.CrossEntropyLoss()  # For multi-class classification\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n\n# Number of epochs\nnum_epochs = 60\n\n# Train the model\ntrain_losses = training_loop(\n    model=model, \n    epochs=num_epochs, \n    optimizer=optimizer, \n    loss_fn=criterion, \n    data_loader=train_loader, \n    device=device\n)\n\n# After training, validate the model\nconf_matrix, val_accuracy, (all_labels, all_preds), fbeta = validation_loop(\n    model, criterion, valid_loader, device\n)","metadata":{"execution":{"iopub.status.busy":"2024-09-20T22:40:33.615474Z","iopub.execute_input":"2024-09-20T22:40:33.615894Z","iopub.status.idle":"2024-09-21T00:02:56.526990Z","shell.execute_reply.started":"2024-09-20T22:40:33.615850Z","shell.execute_reply":"2024-09-21T00:02:56.525808Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/resnet34-b627a593.pth\" to /root/.cache/torch/hub/checkpoints/resnet34-b627a593.pth\n100%|██████████| 83.3M/83.3M [00:00<00:00, 159MB/s] \n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/263 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch [1/60] completed. Avg loss: 2.3242\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/263 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch [2/60] completed. Avg loss: 2.0624\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/263 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch [3/60] completed. Avg loss: 2.1509\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/263 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch [4/60] completed. Avg loss: 1.9680\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/263 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch [5/60] completed. Avg loss: 1.8808\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/263 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch [6/60] completed. Avg loss: 1.7459\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/263 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch [7/60] completed. Avg loss: 1.6775\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/263 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch [8/60] completed. Avg loss: 1.6148\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/263 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch [9/60] completed. Avg loss: 1.5066\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/263 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch [10/60] completed. Avg loss: 1.4472\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/263 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch [11/60] completed. Avg loss: 1.3869\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/263 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch [12/60] completed. Avg loss: 1.3258\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/263 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch [13/60] completed. Avg loss: 1.3274\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/263 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch [14/60] completed. Avg loss: 1.2300\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/263 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch [15/60] completed. Avg loss: 1.2282\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/263 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch [16/60] completed. Avg loss: 1.0975\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/263 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch [17/60] completed. Avg loss: 1.1083\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/263 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch [18/60] completed. Avg loss: 1.0149\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/263 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch [19/60] completed. Avg loss: 0.9624\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/263 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch [20/60] completed. Avg loss: 0.9095\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/263 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch [21/60] completed. Avg loss: 0.8671\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/263 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch [22/60] completed. Avg loss: 0.7828\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/263 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch [23/60] completed. Avg loss: 0.6767\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/263 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch [24/60] completed. Avg loss: 0.6933\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/263 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch [25/60] completed. Avg loss: 0.6597\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/263 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch [26/60] completed. Avg loss: 0.5872\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/263 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch [27/60] completed. Avg loss: 0.4905\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/263 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch [28/60] completed. Avg loss: 0.4698\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/263 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch [29/60] completed. Avg loss: 0.4765\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/263 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch [30/60] completed. Avg loss: 0.3975\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/263 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch [31/60] completed. Avg loss: 0.3163\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/263 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch [32/60] completed. Avg loss: 0.2809\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/263 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch [33/60] completed. Avg loss: 0.4010\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/263 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch [34/60] completed. Avg loss: 0.3339\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/263 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch [35/60] completed. Avg loss: 0.3458\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/263 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch [36/60] completed. Avg loss: 0.2194\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/263 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch [37/60] completed. Avg loss: 0.1687\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/263 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch [38/60] completed. Avg loss: 0.1498\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/263 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch [39/60] completed. Avg loss: 0.2234\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/263 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch [40/60] completed. Avg loss: 0.2365\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/263 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch [41/60] completed. Avg loss: 0.3260\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/263 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch [42/60] completed. Avg loss: 0.1675\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/263 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch [43/60] completed. Avg loss: 0.1225\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/263 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch [44/60] completed. Avg loss: 0.1133\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/263 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch [45/60] completed. Avg loss: 0.1072\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/263 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch [46/60] completed. Avg loss: 0.0872\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/263 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch [47/60] completed. Avg loss: 0.0741\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/263 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch [48/60] completed. Avg loss: 0.0658\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/263 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch [49/60] completed. Avg loss: 0.0656\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/263 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch [50/60] completed. Avg loss: 0.0737\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/263 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch [51/60] completed. Avg loss: 0.0758\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/263 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch [52/60] completed. Avg loss: 0.2325\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/263 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch [53/60] completed. Avg loss: 0.2595\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/263 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch [54/60] completed. Avg loss: 0.0915\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/263 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch [55/60] completed. Avg loss: 0.0794\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/263 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch [56/60] completed. Avg loss: 0.1005\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/263 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch [57/60] completed. Avg loss: 0.0508\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/263 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch [58/60] completed. Avg loss: 0.0505\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/263 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch [59/60] completed. Avg loss: 0.0417\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/263 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch [60/60] completed. Avg loss: 0.0397\nTraining fold 1 completed.\nValidation Error:\n Accuracy: 71.14%, Avg loss: 5.6804\n\nF-beta Score (beta=2): 0.6993\n\n","output_type":"stream"}]},{"cell_type":"code","source":"torch.save(model.state_dict(), 'resnet3_weights.pth')","metadata":{"execution":{"iopub.status.busy":"2024-09-21T00:04:32.475824Z","iopub.execute_input":"2024-09-21T00:04:32.476647Z","iopub.status.idle":"2024-09-21T00:04:32.678550Z","shell.execute_reply.started":"2024-09-21T00:04:32.476603Z","shell.execute_reply":"2024-09-21T00:04:32.677467Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}